{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brainless MSE Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Selector():\n",
    "        \n",
    "        \n",
    "    def ModelSelection(self, folds=10, rstate=420):\n",
    "        \n",
    "        cv = {}\n",
    "        \n",
    "        for name, model in self.Models.items():\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                kfold = model_selection.KFold(n_splits=folds, random_state=rstate) \n",
    "                cv_result = model_selection.cross_val_score(model, self.X, self.y, cv=kfold, scoring='accuracy')\n",
    "                cv[name] = cv_result\n",
    "            \n",
    "            except Exception as e:\n",
    "                \n",
    "                cv[name] = e\n",
    "            \n",
    "\n",
    "        summary = {name: results.mean() for name, results in cv.items()}\n",
    "        \n",
    "        best_model = max(summary, key=summary.get)\n",
    "        best_model = self.Models[best_model]\n",
    "        \n",
    "        self.cv_results = cv\n",
    "        self.model_summary = summary\n",
    "        self.best_model = best_model\n",
    "        \n",
    "    def FeatureSelection(self, folds=10, rstate=420):\n",
    "        \n",
    "        feature_cols = self.X.columns\n",
    "        scores = {}\n",
    "        kfold = model_selection.KFold(n_splits=folds, random_state=rstate)\n",
    "        model = self.best_model\n",
    "        model.fit(self.X, self.y)\n",
    "        mse_scores = -model_selection.cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "        scores[None] = mse_scores\n",
    "        \n",
    "        for dropped_x in feature_cols:\n",
    "    \n",
    "            feature_subset = [item for item in feature_cols if item != dropped_x]\n",
    "            X2 = self.X[feature_subset]\n",
    "            model = self.best_model\n",
    "            model.fit(X2, y)\n",
    "            mse_scores = -model_selection.cross_val_score(model, X2, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "            scores[dropped_x] = mse_scores\n",
    "        \n",
    "        self.feature_scores = scores\n",
    "        \n",
    "        summary = {key: {'MEAN MSE': value.mean(), 'MEAN RMSE': np.sqrt(value).mean()} for key, value in scores.items()}\n",
    "        self.feature_summary = summary \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GenericClassifier(Selector):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.Models = {\n",
    "                       \n",
    "            'LR': LogisticRegression(),\n",
    "            'KNN': KNeighborsClassifier(),\n",
    "            'GBT': GradientBoostingClassifier(),\n",
    "            'NB': GaussianNB(),\n",
    "            'SVM': SVC(),\n",
    "            'DT': DecisionTreeClassifier()\n",
    "        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# K-Fold CV claims to not require a holdout, so concat to avoid throwing away data\n",
    "\n",
    "cable_training = pd.read_csv('./Data/training.csv', na_values=(-999, 6)) # value = 6 corresponds to refusal to answer, 6 nowhere else in data\n",
    "cable_holdout = pd.read_csv('./Data/holdout.csv', na_values=(-999, 6))\n",
    "cable = pd.concat([cable_training, cable_holdout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CleanCableData(df):\n",
    "    \n",
    "    # Since this is a purely exploratory excercise in ML, we have no priors about inappropriate information, beyond the obvious (ID)\n",
    "    \n",
    "    #drop = ['YES', 'ID', 'age', 'class', 'tele_have']\n",
    "    #df['value'] = [(i - 3) for i in df['value']] # Normalize (-2 to +2)\n",
    "    #df = df[[col for col in df.columns if col not in drop]]\n",
    "    \n",
    "    drop = ['ID', 'tele_have']\n",
    "    df = df[[col for col in df.columns if col not in drop]]\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cable = CleanCableData(cable)\n",
    "\n",
    "cable['constant'] = [1 for i in range(len(cable))]\n",
    "\n",
    "y = pd.DataFrame(cable['buy'])\n",
    "X = cable[[col for col in cable.columns if col != 'buy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Model = GenericClassifier(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "Model.ModelSelection(folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = [i[0] for i in Model.best_model.predict_proba(X)] # Model Prediction over training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6928362183754991, 0.30758988015978694)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions) / len(predictions), y.mean()[0] # Far too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Model.FeatureSelection() # Not working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are unsure wether the MSE minimization approach has caused this issue, or if we have simply straw-manned ML by not doing\n",
    "# rigorous data analysis up front; lets try a more reasonable X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CleanCableData(df):\n",
    "    \n",
    "    \n",
    "    drop = ['YES', 'ID', 'age', 'class', 'tele_have']\n",
    "    df['value'] = [(i - 3) for i in df['value']] # Normalize (-2 to +2)\n",
    "    df = df[[col for col in df.columns if col not in drop]]\n",
    "    \n",
    "    df = df[[col for col in df.columns if col not in drop]]\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cable = pd.concat([cable_training, cable_holdout])\n",
    "cable = CleanCableData(cable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model2 = GenericClassifier(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model2.ModelSelection(folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2.best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions2 = [i[1] for i in Model2.best_model.predict_proba(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.30716378162450075, 0.30758988015978694)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions2) / len(predictions2), y.mean()[0] # More in line with expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
